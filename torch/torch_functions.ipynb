{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'add'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\J Narasimha Rao\\Desktop\\Python\\Python Libraries\\torch\\torch_functions.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/J%20Narasimha%20Rao/Desktop/Python/Python%20Libraries/torch/torch_functions.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m l \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([nn\u001b[39m.\u001b[39mLinear(\u001b[39m4\u001b[39m, \u001b[39m4\u001b[39m) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m)])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/J%20Narasimha%20Rao/Desktop/Python/Python%20Libraries/torch/torch_functions.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m m \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(l[\u001b[39m0\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/J%20Narasimha%20Rao/Desktop/Python/Python%20Libraries/torch/torch_functions.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m m\u001b[39m.\u001b[39;49madd(l[\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32me:\\Anaconda Navigator\\lib\\site-packages\\torch\\nn\\modules\\module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1206\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1207\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1208\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'add'"
     ]
    }
   ],
   "source": [
    "l = nn.ModuleList([nn.Linear(4, 4) for i in range(10)])\n",
    "m = nn.Sequential(l[0])\n",
    "m.add(l[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Convolution2d**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(20,4,32,32)\n",
    "conv = nn.Conv2d(4,32,kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 32, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "out = conv(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.7824,  0.8557],\n",
       "          [ 1.4665,  1.6203]],\n",
       "\n",
       "         [[-1.1681, -0.1618],\n",
       "          [-0.7300, -2.2272]],\n",
       "\n",
       "         [[ 0.0684,  0.4227],\n",
       "          [ 1.4472,  0.0936]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3067,  0.1790],\n",
       "          [-2.4943,  0.5529]],\n",
       "\n",
       "         [[-0.5870,  1.0884],\n",
       "          [-0.6585, -0.9977]],\n",
       "\n",
       "         [[-0.4037,  0.1839],\n",
       "          [ 1.4215, -0.0563]]],\n",
       "\n",
       "\n",
       "        [[[-0.4610,  0.7890],\n",
       "          [ 0.1192, -1.4708]],\n",
       "\n",
       "         [[ 0.2918,  1.3851],\n",
       "          [-0.0274,  0.2397]],\n",
       "\n",
       "         [[ 0.9137, -0.3378],\n",
       "          [-0.4931, -0.7996]]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randn(3,3,2,2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.7824,  0.8557],\n",
       "          [ 1.4665,  1.6203]],\n",
       "\n",
       "         [[-1.1681, -0.1618],\n",
       "          [-0.7300, -2.2272]],\n",
       "\n",
       "         [[ 0.0684,  0.4227],\n",
       "          [ 1.4472,  0.0936]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3067,  0.1790],\n",
       "          [-2.4943,  0.5529]],\n",
       "\n",
       "         [[-0.5870,  1.0884],\n",
       "          [-0.6585, -0.9977]],\n",
       "\n",
       "         [[-0.4037,  0.1839],\n",
       "          [ 1.4215, -0.0563]]],\n",
       "\n",
       "\n",
       "        [[[-0.4610,  0.7890],\n",
       "          [ 0.1192, -1.4708]],\n",
       "\n",
       "         [[ 0.2918,  1.3851],\n",
       "          [-0.0274,  0.2397]],\n",
       "\n",
       "         [[ 0.9137, -0.3378],\n",
       "          [-0.4931, -0.7996]]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(3,3,kernel_size=1)\n",
    "nn.Identity()(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 5.],\n",
       "         [3., 4.]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[[1,2]]])\n",
    "b = torch.Tensor([[3],[2]])\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = torch.Tensor([1,2,3])\n",
    "a2 = torch.Tensor([1,2,3])\n",
    "res = torch.cat((a1,a2),dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 1., 2., 3.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.tensor([[1, 2], [3, 4]])\n",
    "tensor2 = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "# Concatenate along the last dimension (dimension -1)\n",
    "result = torch.cat((tensor1, tensor2),dim=-1)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position Encoding\n",
    "x =25\n",
    "device = x.devi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(2, 12, 10, 10)\n",
    "# Separate 6 channels into 3 groups\n",
    "# m = nn.GroupNorm(3, 6)\n",
    "# Separate 6 channels into 6 groups (equivalent with InstanceNorm)\n",
    "# m = nn.GroupNorm(6, 6)\n",
    "# Put all 6 channels into a single group (equivalent with LayerNorm)\n",
    "m = nn.GroupNorm(1, 12)\n",
    "# Activating the module\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4282e-01, -8.9297e-01,  1.6769e-01,  9.1209e-02, -1.8033e-01,\n",
       "          5.1848e-01, -1.8393e-01, -9.1947e-01,  4.8938e-01,  8.7808e-02],\n",
       "        [-7.1632e-01, -7.6656e-02, -3.6821e-02, -8.0401e-01,  6.5570e-01,\n",
       "          1.2206e-02,  7.9335e-01,  8.8404e-01,  5.0927e-06, -9.7527e-01],\n",
       "        [-1.2649e+00,  9.6975e-01,  8.2400e-01,  1.3851e+00,  2.5481e-02,\n",
       "          1.2066e+00, -1.5203e+00,  7.7815e-01, -1.5145e+00,  1.4440e+00],\n",
       "        [-2.0199e+00,  6.0005e-02,  1.2282e+00,  8.4320e-01,  1.4218e+00,\n",
       "         -5.7969e-01, -2.3008e-01,  2.3765e-01, -6.5817e-01,  3.5241e-01],\n",
       "        [-8.3671e-01,  7.0779e-01, -3.1955e-01, -1.6714e+00, -1.3844e-01,\n",
       "          2.6609e+00,  1.2938e+00, -4.8768e-01,  9.1378e-01, -6.1546e-01],\n",
       "        [-6.6937e-02, -3.4550e-02,  1.6667e+00,  6.3910e-02,  1.2450e+00,\n",
       "         -8.2502e-02,  6.0486e-01, -2.6574e-01,  4.7956e-01,  7.8662e-01],\n",
       "        [-5.4048e-01,  2.4659e+00, -3.0121e+00,  1.2592e+00,  6.8575e-01,\n",
       "         -1.0281e+00, -2.8913e-01, -8.9425e-02, -1.0002e+00,  8.3342e-01],\n",
       "        [-9.8022e-01,  1.4960e+00,  7.9247e-02,  9.6259e-02,  5.0737e-01,\n",
       "          2.3295e+00,  1.0819e+00,  7.4720e-01, -6.7981e-01,  3.5249e-01],\n",
       "        [ 1.4222e-01,  3.5387e-01, -2.8952e-01, -1.2507e+00, -1.5995e-01,\n",
       "          1.2797e+00,  6.3724e-01, -1.6599e+00, -1.0360e+00, -8.9408e-01],\n",
       "        [-2.0216e+00,  3.2882e-01,  1.3577e+00, -2.6840e-01, -1.1638e-01,\n",
       "          6.8269e-01, -8.3709e-01, -1.1112e+00, -7.3762e-01, -8.2855e-01]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1632, -0.9332,  0.1895,  0.1085, -0.1789,  0.5608, -0.1827, -0.9613,\n",
       "          0.5300,  0.1049],\n",
       "        [-0.7463, -0.0691, -0.0270, -0.8391,  0.7061,  0.0249,  0.8518,  0.9478,\n",
       "          0.0120, -1.0204],\n",
       "        [-1.3270,  1.0385,  0.8842,  1.4781,  0.0390,  1.2892, -1.5973,  0.8357,\n",
       "         -1.5911,  1.5405],\n",
       "        [-2.1262,  0.0755,  1.3121,  0.9046,  1.5170, -0.6016, -0.2316,  0.2636,\n",
       "         -0.6847,  0.3850],\n",
       "        [-0.8737,  0.7612, -0.3263, -1.7572, -0.1345,  2.8286,  1.3816, -0.5042,\n",
       "          0.9793, -0.6395],\n",
       "        [-0.0589, -0.0246,  1.7763,  0.0796,  1.3298, -0.0753,  0.6523, -0.2693,\n",
       "          0.5196,  0.8447],\n",
       "        [-0.5601,  2.6222, -3.1765,  1.3449,  0.7379, -1.0763, -0.2941, -0.0827,\n",
       "         -1.0468,  0.8942],\n",
       "        [-1.0256,  1.5956,  0.0959,  0.1139,  0.5491,  2.4779,  1.1573,  0.8029,\n",
       "         -0.7076,  0.3851],\n",
       "        [ 0.1625,  0.3866, -0.2945, -1.3120, -0.1573,  1.3666,  0.6865, -1.7451,\n",
       "         -1.0847, -0.9344],\n",
       "        [-2.1279,  0.3601,  1.4492, -0.2721, -0.1112,  0.7347, -0.8741, -1.1643,\n",
       "         -0.7688, -0.8650]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected weight to be a vector of size equal to the number of channels in input, but got weight of shape [6] and input of shape [2, 2, 10, 10]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\J Narasimha Rao\\Desktop\\Python\\Python Libraries\\torch\\torch_functions.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/J%20Narasimha%20Rao/Desktop/Python/Python%20Libraries/torch/torch_functions.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m m \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mGroupNorm(\u001b[39m1\u001b[39m, \u001b[39m6\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/J%20Narasimha%20Rao/Desktop/Python/Python%20Libraries/torch/torch_functions.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Activating the module\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/J%20Narasimha%20Rao/Desktop/Python/Python%20Libraries/torch/torch_functions.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m output \u001b[39m=\u001b[39m m(\u001b[39minput\u001b[39;49m)\n",
      "File \u001b[1;32me:\\Anaconda Navigator\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\Anaconda Navigator\\lib\\site-packages\\torch\\nn\\modules\\normalization.py:272\u001b[0m, in \u001b[0;36mGroupNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 272\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mgroup_norm(\n\u001b[0;32m    273\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_groups, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps)\n",
      "File \u001b[1;32me:\\Anaconda Navigator\\lib\\site-packages\\torch\\nn\\functional.py:2516\u001b[0m, in \u001b[0;36mgroup_norm\u001b[1;34m(input, num_groups, weight, bias, eps)\u001b[0m\n\u001b[0;32m   2514\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(group_norm, (\u001b[39minput\u001b[39m, weight, bias,), \u001b[39minput\u001b[39m, num_groups, weight\u001b[39m=\u001b[39mweight, bias\u001b[39m=\u001b[39mbias, eps\u001b[39m=\u001b[39meps)\n\u001b[0;32m   2515\u001b[0m _verify_batch_size([\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m*\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m num_groups, num_groups] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()[\u001b[39m2\u001b[39m:]))\n\u001b[1;32m-> 2516\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mgroup_norm(\u001b[39minput\u001b[39;49m, num_groups, weight, bias, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected weight to be a vector of size equal to the number of channels in input, but got weight of shape [6] and input of shape [2, 2, 10, 10]"
     ]
    }
   ],
   "source": [
    "# Separate 6 channels into 3 groups\n",
    "m = nn.GroupNorm(3, 6)\n",
    "# Separate 6 channels into 6 groups (equivalent with InstanceNorm)\n",
    "m = nn.GroupNorm(6, 6)\n",
    "# Put all 6 channels into a single group (equivalent with LayerNorm)\n",
    "m = nn.GroupNorm(1, 6)\n",
    "# Activating the module\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9862, 0.1829, 0.6722, 0.2753],\n",
      "         [0.8016, 0.8004, 0.9893, 0.9158]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1,2,4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3841,  0.5012, -0.0477],\n",
       "         [ 0.5328,  0.4279,  0.0402]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = nn.Linear(4,3)\n",
    "l(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = l.state_dict()['weight']\n",
    "b = l.state_dict()['bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3136,  0.0834, -0.3261])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3841,  0.5012, -0.0477],\n",
       "         [ 0.5328,  0.4279,  0.0402]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a @ w.T + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4364, 0.8492, 0.0646, 0.2669, 0.1412],\n",
      "         [0.7550, 0.6535, 0.3296, 0.6113, 0.7643],\n",
      "         [0.2613, 0.0259, 0.1684, 0.0627, 0.9979],\n",
      "         [0.0401, 0.1605, 0.0653, 0.4228, 0.0393],\n",
      "         [0.0858, 0.1712, 0.8225, 0.5533, 0.0159]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1,5,5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = nn.Conv2d(1,3,kernel_size=2)\n",
    "out = c(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0249,  0.6282,  0.4944,  0.6134],\n",
      "         [ 0.6748,  0.4176,  0.5531,  0.7409],\n",
      "         [ 0.2202,  0.2945,  0.2690,  0.8083],\n",
      "         [ 0.2726,  0.3688,  0.7849,  0.4657]],\n",
      "\n",
      "        [[ 0.0315,  0.2776, -0.0771, -0.1134],\n",
      "         [ 0.4732,  0.3914,  0.2986,  0.0838],\n",
      "         [ 0.2075,  0.1391,  0.0672,  0.1864],\n",
      "         [ 0.1164, -0.1085, -0.1278,  0.2404]],\n",
      "\n",
      "        [[ 0.5893,  0.3278,  0.5994,  0.5763],\n",
      "         [ 0.3181,  0.2984,  0.4581,  0.4230],\n",
      "         [ 0.4196,  0.5320,  0.4823,  0.6318],\n",
      "         [ 0.5214,  0.5362,  0.6946,  0.4402]]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = c.state_dict()['weight']\n",
    "b = c.state_dict()['bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1511,  0.4729],\n",
       "          [ 0.4548,  0.1293]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4069,  0.0822],\n",
       "          [-0.1747, -0.3856]]],\n",
       "\n",
       "\n",
       "        [[[-0.3689,  0.0834],\n",
       "          [ 0.1766,  0.0799]]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Sol at 0x2845f3950f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Sol:\n",
    "    def __init__(self,a,b) -> int:\n",
    "        a = self.x(a,b)\n",
    "        print(a)\n",
    "    def x(self,a,b):\n",
    "        return a*b\n",
    "Sol(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
