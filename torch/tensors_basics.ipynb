{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PyTorch**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tensors**\n",
    "A tensor is a high dimensional vectors. It is generalization of vectors and matrices and is easily understood as a multidimensional array.It is a term and set of techniques known in machine learning in the training and operation of deep learning models can be described in terms of tensors. In many cases tensors are used as a replacement for NumPy to use the power of GPUs.\n",
    "\n",
    "Tensors are a type of data structure used in linear algebra, and like vectors and matrices, you can calculate arithmetic operations with tensors.\n",
    "\n",
    "##### **Why Tensors**\n",
    "Here are some reasons why tensors are preferred:\n",
    "\n",
    "Efficient computations: Tensors are designed to efficiently handle computations involving multi-dimensional arrays, especially in large-scale applications. Libraries optimized for tensor operations can leverage hardware acceleration, such as GPUs or specialized tensor processing units (TPUs), to perform computations faster than numpy arrays.\n",
    "\n",
    "Automatic differentiation: Tensors often come with built-in support for automatic differentiation, which is essential for training deep neural networks and optimizing complex mathematical models. This capability enables efficient computation of gradients, which are crucial in optimization algorithms like backpropagation.\n",
    "\n",
    "Hardware compatibility: Tensors are compatible with specialized hardware architectures, such as GPUs, TPUs, and quantum processing units (QPUs), which can significantly speed up computations for certain applications. These hardware accelerators are designed to efficiently process tensors and can deliver substantial performance gains over traditional CPUs.\n",
    "\n",
    "Quantum computing: Tensors are used in quantum computing frameworks like TensorFlow Quantum (TFQ) and PennyLane. These frameworks enable the integration of quantum circuits with classical machine learning models and provide tools for training and optimizing quantum circuits. Tensors allow for efficient representation and manipulation of quantum states, measurements, and operators.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Convert numpy to tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4],\n",
      "        [0, 9, 2, 0]], dtype=torch.int32)\n",
      "Shape: torch.Size([2, 4])\n",
      "First Element: 1\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[1,2,3,4],[0,9,2,0]])\n",
    "y=torch.from_numpy(x)\n",
    "print(y)\n",
    "\n",
    "# Know the shape of tensor\n",
    "shape = y.size()            # y.shape also gives shape \n",
    "print(\"Shape: {}\".format(shape))\n",
    "print(\"First Element: {}\".format(y[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [0, 9]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(y[:,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   2, 100,   4],\n",
       "       [  0,   9,   2,   0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Disadvantage of from_numpy. The array and tensor uses the same memory location.\n",
    "# Change of element in a tensor reflects the change in array\n",
    "y[0][2]=100\n",
    "x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   2, 100,   4],\n",
       "        [  0,   9,   2,   0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To overcome this we use tensor\n",
    "z=torch.tensor(x)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[5.9605e-08, 0.0000e+00, 1.1921e-07, 0.0000e+00],\n",
       "          [1.7881e-07, 0.0000e+00, 2.3842e-07, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 0.0000e+00, 5.3644e-07, 0.0000e+00],\n",
       "          [1.1921e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]],\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping in torch\n",
    "w = y.view(2,1,2,2)\n",
    "w.view(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data type\n",
    "w.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2, -1,  2, 11, 21],\n",
       "        [ 3,  4,  0,  7,  3,  4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatination of tensors\n",
    "a=torch.tensor([[1,2],[3,4]])\n",
    "b=torch.tensor([[-1,2],[0,7]])\n",
    "c=torch.tensor([[11,21],[3,4]])\n",
    "concat_tensor=torch.cat([a,b,c],dim = 1)\n",
    "concat_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# ones\n",
    "one = torch.ones(2,3)\n",
    "print(one)\n",
    "# zero\n",
    "zero = torch.zeros(2,3)\n",
    "print(zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    # It has two procedures\n",
    "    x=torch.ones(5,device=device)   # ---> 1\n",
    "    a=a.to(device)                  # ---> 2\n",
    "print(x)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Using random**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Arithematic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 7.,  9., 11.],\n",
      "         [ 3., 13.,  6.]]])\n"
     ]
    }
   ],
   "source": [
    "# adding two tensors\n",
    "a = torch.tensor([3,4,5], dtype=torch.float)\n",
    "b = torch.tensor([[[4,5,6],[0,9,1]]], dtype=torch.float)\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 7, 9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summing up tensor\n",
    "x = torch.tensor([[2,3,4],[3,4,5]])\n",
    "x.sum(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(62.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dot product\n",
    "dot_product=a.dot(b)\n",
    "dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12., 20., 30.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication\n",
    "a.mul(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8, -9, -2,  0],\n",
       "        [ 8,  0, -8,  0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1=torch.tensor([[2,3],[8,0]])\n",
    "tensor2=torch.tensor([[1,0,-1,0],[2,-3,0,0]])\n",
    "torch.matmul(tensor1,tensor2) \n",
    "# tensor.mm(tensor1,tensor2) & tensor1 @ tensor2 gives same result as matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8, -9, -2,  0],\n",
       "        [ 8,  0, -8,  0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 @ tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equal \n",
    "torch.equal(tensor1,tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 0, 7, 9, 8, 7, 6, 8])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the parameters of the uniform distribution\n",
    "low = 0\n",
    "high = 10\n",
    "shape = (5,)  # Example: Generate 5 samples\n",
    "\n",
    "# Generate random samples from a uniform distribution\n",
    "uniform_samples = torch.randint(0,11,(8,))\n",
    "uniform_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6976, 0.6577, 0.6855, 0.9345, 0.9312, 0.1336, 0.3420, 0.9478, 0.7107,\n",
       "        0.1880, 0.7228, 0.6941, 0.1840, 0.6336, 0.7945, 0.0130, 0.3208, 0.1336,\n",
       "        0.4418, 0.5005])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(20)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7107, 0.6976, 0.9478, 0.1880, 0.7107, 0.9478, 0.3420, 0.7107])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = a.gather(-1,uniform_samples)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape = out.reshape(8,*(1,1,1))\n",
    "reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[2.4003e-01, 4.8137e-01, 3.2150e-01],\n",
       "          [1.8798e-02, 5.4820e-01, 4.3689e-01],\n",
       "          [6.6130e-01, 6.3981e-01, 2.9848e-01]],\n",
       "\n",
       "         [[9.8741e-02, 2.1560e-01, 1.4765e-01],\n",
       "          [5.9240e-01, 2.4195e-01, 2.5344e-02],\n",
       "          [6.8464e-01, 6.0285e-01, 6.5976e-01]]],\n",
       "\n",
       "\n",
       "        [[[5.4840e-01, 5.2073e-01, 5.9881e-01],\n",
       "          [5.6088e-01, 1.1937e-02, 1.4825e-01],\n",
       "          [3.4975e-01, 4.2459e-01, 4.7161e-01]],\n",
       "\n",
       "         [[4.9377e-01, 1.3950e-01, 1.6011e-01],\n",
       "          [3.9418e-01, 5.0169e-01, 6.7091e-01],\n",
       "          [3.4537e-01, 4.7111e-01, 8.6552e-02]]],\n",
       "\n",
       "\n",
       "        [[[3.8379e-01, 7.8955e-02, 3.6815e-01],\n",
       "          [2.5691e-01, 3.3868e-01, 1.4155e-01],\n",
       "          [2.0601e-01, 7.9533e-02, 5.7876e-01]],\n",
       "\n",
       "         [[4.2005e-01, 3.6125e-02, 2.7469e-01],\n",
       "          [1.3643e-01, 8.8086e-01, 7.4608e-01],\n",
       "          [4.6831e-01, 6.5996e-01, 4.4732e-01]]],\n",
       "\n",
       "\n",
       "        [[[3.2185e-02, 1.0693e-01, 1.2142e-01],\n",
       "          [1.1546e-01, 5.2338e-02, 1.8025e-02],\n",
       "          [3.7666e-02, 1.3475e-01, 5.8635e-02]],\n",
       "\n",
       "         [[4.5514e-02, 3.5745e-02, 7.6703e-02],\n",
       "          [1.4559e-01, 3.5062e-04, 4.4719e-02],\n",
       "          [1.5975e-01, 1.7023e-01, 1.4070e-01]]],\n",
       "\n",
       "\n",
       "        [[[5.9972e-01, 3.2086e-01, 7.0196e-01],\n",
       "          [2.5488e-03, 2.7123e-01, 1.5457e-01],\n",
       "          [5.0395e-01, 5.4547e-02, 3.6643e-01]],\n",
       "\n",
       "         [[6.8162e-01, 1.1150e-01, 4.9522e-01],\n",
       "          [1.5458e-01, 3.8424e-02, 4.8650e-01],\n",
       "          [2.9331e-01, 4.7521e-01, 3.3325e-01]]],\n",
       "\n",
       "\n",
       "        [[[6.0040e-02, 4.9453e-01, 1.4879e-01],\n",
       "          [7.6069e-02, 1.3763e-02, 5.3698e-01],\n",
       "          [2.2629e-01, 1.1446e-01, 1.9724e-02]],\n",
       "\n",
       "         [[1.2479e-01, 6.2550e-01, 9.9894e-02],\n",
       "          [1.5453e-02, 5.8679e-01, 6.4896e-01],\n",
       "          [1.1163e-01, 4.6330e-01, 5.8016e-01]]],\n",
       "\n",
       "\n",
       "        [[[1.9659e-02, 2.9568e-01, 2.2208e-01],\n",
       "          [1.6809e-01, 4.9576e-02, 2.2615e-02],\n",
       "          [1.7605e-01, 2.0911e-01, 1.6538e-01]],\n",
       "\n",
       "         [[3.0138e-03, 5.1359e-02, 1.3909e-02],\n",
       "          [1.2645e-01, 1.8108e-01, 3.0836e-01],\n",
       "          [2.5547e-02, 1.9757e-01, 2.1229e-01]]],\n",
       "\n",
       "\n",
       "        [[[5.8961e-01, 4.9015e-01, 4.9838e-01],\n",
       "          [5.2932e-01, 5.8329e-01, 4.0879e-01],\n",
       "          [8.1939e-02, 3.3928e-01, 5.7431e-01]],\n",
       "\n",
       "         [[9.4272e-02, 3.9347e-01, 6.9287e-02],\n",
       "          [6.4648e-01, 4.0135e-01, 4.2574e-03],\n",
       "          [9.8155e-02, 3.9775e-01, 6.3192e-01]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(8,2,3,3)\n",
    "reshape*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.random.uniform(minval=0,maxval=10,shape=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "out = tf.gather(a, t)\n",
    "tf.reshape(out, [batch_size, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  6, 24])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "np.cumprod(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "16\n",
      "81\n",
      "25\n",
      "Function used in partial function pow2 : <function power at 0x0000028C5CAD6B00>\n",
      "Default keywords for pow2 : {'b': 2}\n",
      "Default arguments for power_of_5 : (5,)\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "def power(a, b):\n",
    "\treturn a**b\n",
    "\n",
    "\n",
    "# partial functions\n",
    "pow2 = partial(power, b=2)\n",
    "pow4 = partial(power, b=4)\n",
    "power_of_5 = partial(power, 5)\n",
    "\n",
    "print(power(2, 3))\n",
    "print(pow2(4))\n",
    "print(pow4(3))\n",
    "print(power_of_5(2))\n",
    "\n",
    "print('Function used in partial function pow2 :', pow2.func)\n",
    "print('Default keywords for pow2 :', pow2.keywords)\n",
    "print('Default arguments for power_of_5 :', power_of_5.args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2,3,3)\n",
    "y = torch.tensor([[[1]],[[2]]])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 3 but got size 1 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\J Narasimha Rao\\Desktop\\Python\\Python Libraries\\torch\\tensors_basics.ipynb Cell 37\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/J%20Narasimha%20Rao/Desktop/Python/Python%20Libraries/torch/tensors_basics.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49mhstack((x,y))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 3 but got size 1 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "torch.hstack((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,2,2,6)\n",
    "y = torch.rand(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0460, 0.8391, 0.8419, 0.5433, 0.2567, 0.8239]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4184, 1.1622, 1.4038, 1.2493, 0.3959, 1.7287],\n",
       "          [0.7246, 1.2494, 1.0523, 0.7158, 0.9759, 1.3661]],\n",
       "\n",
       "         [[0.2490, 0.9657, 1.6965, 0.9665, 0.4984, 1.6890],\n",
       "          [0.1820, 1.4850, 1.7123, 1.5111, 0.8565, 1.3170]]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9645, 0.2420, 0.5812, 0.0685, 0.1389, 0.3207]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = nn.Linear(6,10)(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 1, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:,:,None,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1083, 0.2939, 0.8936, 0.3931, 0.9973, 0.6533],\n",
       "          [0.0097, 0.1256, 0.0123, 0.9587, 0.1785, 0.8416]],\n",
       "\n",
       "         [[0.3275, 0.1388, 0.6699, 0.4605, 0.4057, 0.2284],\n",
       "          [0.3631, 0.3007, 0.9718, 0.0126, 0.4485, 0.0169]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1764, 0.4936, 1.0353, 0.7609, 1.1759, 0.7988],\n",
       "          [0.1618, 0.7361, 0.0273, 1.9294, 0.3775, 1.5512]],\n",
       "\n",
       "         [[0.3956, 0.3385, 0.8116, 0.8282, 0.5843, 0.3739],\n",
       "          [0.5152, 0.9113, 0.9868, 0.9832, 0.6476, 0.7265]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural:\n",
    "    def __init__(self) -> None:\n",
    "        self.l = nn.Linear(2,3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.l(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0652, 0.5334]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(1,2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1057, -0.5522,  0.0108]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = Neural()\n",
    "n.forward(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([1,2,3,4])\n",
    "np.append(0,x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
